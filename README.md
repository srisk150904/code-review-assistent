# ğŸš€ Code Review Assistant

An automated **code review system** that analyzes uploaded code files or pasted snippets for **readability, modularity, and potential bugs**, combining **static analysis** + **LLM suggestions**.

This project is part of a **placement evaluation** and demonstrates:

* **API design with FastAPI**
* **Static code analysis (Python AST)**
* **LLM integration (mock/real)**
* **Frontend with Streamlit**

---

## ğŸŒ Live Demo (No Setup Needed)

* **Frontend (Streamlit UI):**
  ğŸ‘‰ [https://code-review-assistent-qvuhqoctvu65sxxxszt2uy.streamlit.app](https://code-review-assistent-qvuhqoctvu65sxxxszt2uy.streamlit.app)

* **Backend (FastAPI API + Docs):**
  ğŸ‘‰ [https://code-review-assistent.onrender.com/docs](https://code-review-assistent.onrender.com/docs)

âš¡ Evaluators can directly use the **Streamlit app** link. The backend is deployed separately and powers the app.

---

## ğŸ“‚ Project Structure

```
code-review-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # FastAPI app (main entry)
â”‚   â”œâ”€â”€ llm.py              # LLM integration (mock/real)
â”‚   â”œâ”€â”€ analyzers/
â”‚   â”‚   â””â”€â”€ python_static.py # Python AST static analyzer
â”‚   â”œâ”€â”€ models.py           # SQLModel schema + DB helpers
â”‚   â”œâ”€â”€ schemas.py          # Request/response schemas
â”‚   â”œâ”€â”€ settings.py         # Config & environment variables
â”‚   â””â”€â”€ utils.py            # File handling utilities
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ sample.py           # Example test file
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api_smoke.py   # Simple test scaffold
â”œâ”€â”€ frontend.py             # Streamlit UI
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Documentation
```

---

## ğŸ”§ Local Setup (Optional)

> âš ï¸ You donâ€™t need to run locally for demo â€” only if you want to test/develop.

1. Clone repo & enter folder

   ```bash
   git clone <repo-url>
   cd code-review-assistant
   ```

2. Create & activate virtual environment

   ```bash
   python -m venv .venv
   # Windows
   .venv\Scripts\activate
   # Linux/Mac
   source .venv/bin/activate
   ```

3. Install dependencies

   ```bash
   pip install -r requirements.txt
   ```

4. Run backend

   ```bash
   uvicorn backend.app:app --reload
   ```

   Visit â†’ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

5. Run frontend

   ```bash
   streamlit run frontend.py
   ```

   Visit â†’ [http://localhost:8501](http://localhost:8501)

---

## ğŸ¯ How It Works

1. **Input** â†’ Upload Python file or paste code.
2. **Static Analysis** â†’ AST parsing detects:

   * Functions, arguments, docstrings
   * Cyclomatic complexity
   * Missing error handling, style issues
3. **LLM Suggestions** â†’

   * If `OPENAI_API_KEY` is set â†’ sends findings to LLM (GPT)
   * If not â†’ returns mock suggestions for demo
4. **Storage** â†’ Results stored in SQLite (`reviews.db`).
5. **Output** â†’ JSON + interactive UI with:

   * Score
   * Summary
   * Suggestions
   * Static findings

---

## âœ… Example Workflow

1. Open **Streamlit app**:
   ğŸ‘‰ [https://code-review-assistent-qvuhqoctvu65sxxxszt2uy.streamlit.app](https://code-review-assistent-qvuhqoctvu65sxxxszt2uy.streamlit.app)

2. Upload a Python file (e.g. `examples/sample.py`).

3. Get results:

   * Score (0â€“100) with progress bar
   * Summary of code quality
   * Improvement suggestions
   * Static analysis findings

4. Click **View All Reports** to see history.

---

## ğŸ“Œ Notes

* âœ… Works fully online (Streamlit + Render).
* âœ… No local setup needed for evaluators.
* âš ï¸ On free tier, backend (Render) may â€œsleepâ€ if idle; first request can take ~15 sec.
* ğŸ§© With `OPENAI_API_KEY`, real LLM insights can be enabled; otherwise, mock responses are shown.

---

âœ¨ With this README, an evaluator can:

* **Directly test** the project via Streamlit link.
* **Inspect backend API** via Render link.
* Optionally, **run locally** for development.

---
